---
title: "Simulation Recreation"
author: "Hillary Heiling"
date: "September 8, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section 2 Example

Recreation of one of the simulations in Section 2 of Raftery et al. (Estimating the integrating likelihood via posterior simulation using the harmonic mean identity)

Description of simulation: We are interested in the marginal likelihood for a single data point y

$$ y \sim N(\mu, \frac{1}{\psi}) $$

$$ \psi \sim Gamma(\alpha / 2, \alpha / 2) $$

Paper prior specification:
$$ \mu|\psi \sim N(\mu_0, n_0 \psi) $$

Correction to make things conjugate (I think), as the paper claims these priors are:

$$ \mu|\psi \sim N(\mu_0, n_0 \psi^{-1}) $$

Integrated likelihood analytical result:

$$ f(y) = St(y|\mu_0,\lambda = n_0/(n_0+1),\alpha) = \frac{\Gamma(\frac{1}{2}(\alpha+1))}{\Gamma(\frac{1}{2}\alpha)} \left ( \frac{\lambda}{\alpha \pi} \right)^{1/2} * [1 + \alpha^{-1} \lambda (y-\mu_0)^2]^{-(\alpha+1)/2} $$

Let the hyperparameters have the following values:

$ \mu_0 = 0, \alpha = 2, n_0 = 1 $

Target value:

```{r}
alpha = 2
mu = 0
y = 5
n0 = 1
lambda = n0 / (1+n0)

(f_y = gamma(0.5*(alpha+1)) / gamma(0.5*alpha) * (lambda / alpha / pi)^0.5 * 
  (1 + 1/alpha*lambda*(y-mu)^2)^((-1)*(alpha+1)/2))

# In harmonic mean functions, will shoot for following target value:
1/f_y

```

Note: Raftery et al. also used the following combinations: y = {5,3,0}, alpha = {2,6,10}, $\mu_0$ remained equal to 0.

## Gathering the MCMC samples

Gibbs approach: Sample $\psi$ from appropriate gamma dist and then sample $\mu$ based on given $\psi$ sample. ($\psi$ does not depend on $\mu$, so can independently sample $\psi$ from the specified gamma dist).

$$ \psi^{-1}|y \sim IG(\alpha/2, \alpha/2) \rightarrow \psi|y \sim Gamma(\alpha/2,\alpha/2) $$

Note: In general for multiple data points:

$$ \psi|y_1,...,y_n \sim Gamma(\alpha/2 + n/2 - 1/2, \alpha/2 + 1/2 \sum (y_i - \bar y)^2) $$
$$ \mu | \psi,y \sim N \left (\frac{y}{2}, \frac{\psi^{-1}}{2} \right) $$

Note: In general for multiple data points:

$$ \mu | \psi,y \sim N \left (\frac{n \bar y + \mu_0}{n + 1}, \frac{\psi^{-1}}{n + 1} \right) $$

```{r}
draws = function(mu0, alpha, M, y){
  
  psi = rgamma(M, shape = alpha / 2, scale = alpha / 2)
  mu = rnorm(M, mean = y/2, sd = sqrt(1/psi/2))
  
  return(cbind(mu,psi))
}
```


## Evaluating the Modified and Regular Harmonic Mean estimates using the MCMC samples

Once we have the MCMC samples, we can plug them into the (modified) harmonic mean functions. Returned value should be near target value given above.

```{r}
HM_sect2 = function(MCMC, y){
  mu = MCMC[,1]
  psi = MCMC[,2] # precision of y; inverse of variance of y
  sd_y = sqrt(1/psi)
  dens = dnorm(y, mean = mu, sd = sd_y)
  inv_dens = 1 / dens
  
  # marg_lik = 1 / mean(inv_dens)
  # ll = log(marg_lik)
  
  return(mean(inv_dens))
}

mod_HM_sect2 = function(MCMC, y, mu0, alpha, p){
  mu = MCMC[,1]
  psi = MCMC[,2]
  sd_y = sqrt(1/psi)
  
  # Calculation of denominator 
  dens = dnorm(y, mean = mu, sd = sd_y)
  prior = dnorm(mu, mean = mu0, sd = sqrt(1/psi)) * dgamma(psi, shape = alpha/2, scale = alpha/2)
  
  # Calculation of numerator
  # Posterior modes and covariance:
  mode = colMeans(MCMC)
  sigma = cov(MCMC)
  # Calculation of truncated normal:
  wt_norm = dmvnorm(MCMC, mean = mode, sigma = sigma)
  region = apply(MCMC, 1, function(x) t(x - mode) %*% solve(sigma) %*% (x - mode))
  cutoff = qchisq(p = p, df = 2) # df = number parameters, mu and psi
  trunc_norm = ifelse(region > cutoff, 0, wt_norm)
  print("proportion truncated:")
  print(sum(region > cutoff) / length(region))
  
  if(anyNA(trunc_norm)) print(sum(is.na(trunc_norm)))
  
  components = trunc_norm / (dens * prior)
  inv_lik = mean(components)
  # ll = log(1/inv_lik)
  
  return(inv_lik)
}
```

Results:

```{r}
library(mvtnorm)
mcmc_samps = draws(mu0 = 0, alpha = 2, 10^4, y = 5)

HM_sect2(mcmc_samps, 0)
mod_HM_sect2(mcmc_samps, y = 5, mu0 = 0, alpha = 2, p = 0.98)
```

# Section 4.2 Example

y distribution: 

$$ y_1,...,y_n \sim N(\mu,I) $$

Prior for mean:

$$ \mu \sim N(0,I) $$
Posterior for mean:

$$ \mu|y \sim N \left ( \frac{n \bar y}{n+1}, \frac{I}{n+1} \right ) $$
True log integrated likelihood value:

$$ \ell(y) = log(f(y)) = \frac{d}{2} log \left( \frac{n}{(n+1)2\pi} \right ) - \frac{n}{2(n+1)} \sum_{j=1}^d \bar y_j^2 $$

Let us assign the following values to the hyperparameters:

$ \mu = 0.15, n = 50, d = 3 $

## Evaluate Target Log-Likelihood log(f(y)) and Related Values

The function:

```{r}

ll = function(d, n, y){
  y_means = colMeans(y)
  ll = d/2 * log(n/(2*pi*(n+1))) - n/(2*(n+1)) * sum(y_means^2)
}

```

## Sample y and posterior samples of $\mu$

Also, evaluate target loglik

```{r}
library(mvtnorm)
mu0 = 0.15 # for all dimensions of y
n = 100
d = 3
I = diag(x = 1, nrow = d)
M = 10^4

y = rmvnorm(n = n, mean = rep(mu0, times = d), sigma = I)

post_mu = rmvnorm(n = M, mean = colSums(y)/(n+1), sigma = I/(n+1))

# Target log-lik:
target = ll(d, n, y)
target # log-lik
exp(target) # marginal/integrated likelihood
1/exp(target) # inverse of marginal likelihood
```

## (Modified) Harmonic Mean Estimate

```{r}

HM = function(posterior, y){
  # Define variables
  d = ncol(y)
  n = nrow(y)
  M = nrow(posterior)
  I = diag(x = 1, nrow = d)
  
  ll = 0
  dens = matrix(0, nrow = n, ncol = M)
  # For each posterior draw u, calculate y|u density
  ## Organization: row = y_i, column = draw_s
  for(s in 1:M){
    dens[,s] = dmvnorm(y, mean = posterior[s,], sigma = I)
  }
  # Find inverse of densities
  inv_dens = 1/dens
  # Sum inverse densities for each individual - inverse likelihood for each individual
  inv_lik = rowMeans(inv_dens)
  # Inverse of inverse-likelihood = likelihood
  lik = 1 / inv_lik
  # Sum log of individual likelihoods
  ll = sum(log(lik))
  
  return(ll)
}

mod_HM = function(posterior, y, mu0, p){
  # Define variables
  n = nrow(y)
  M = nrow(posterior)
  d = ncol(y)
  I = diag(x=1,nrow=d)
  
  ll = 0
  # Organization of density matrix: rows = individuals, columns = posterior draws
  dens = matrix(0, nrow = n, ncol = M)
  
  # Calculate posterior modes and covariance (for numerator)
  post_means = colMeans(posterior)
  post_cov = cov(posterior)
  
  # Denominator component - prior evaluated at posterior sample values
  prior = matrix(dmvnorm(posterior, mean = rep(mu0, times = d), sigma = I), nrow = 1)
  # Calculation of truncated normal - numerator
  wt_norm = dmvnorm(posterior, mean = post_means, sigma = post_cov)
  region = apply(posterior, 1, function(x) t(x - post_means) %*% solve(post_cov) %*% 
                   (x - post_means))
  cutoff = qchisq(p=p, df=d)
  trunc_norm = matrix(ifelse(region>cutoff, 0, wt_norm), nrow = 1)
  print("proportion truncated:")
  print(sum(region>cutoff) / length(region))
  
  for(s in 1:M){
    dens[,s] = dmvnorm(y, mean = posterior[s,], sigma = I)
  }
  
  # Calculate f* / (denity * prior)
  components = trunc_norm[rep(1, times = n),] / (dens * prior[rep(1, times = n),])
  # Sum these components over all posterior draws to get inverse-likelihood for each individual
  inv_lik = rowMeans(components)
  # Find likelihood (inverse of inverse), then sum logs of these likelihoods
  ll = sum(log(1/inv_lik))
  
  return(ll)
}
```

```{r}
HM(post_mu, y)
mod_HM(post_mu, y, mu0=0.15, p=0.98)
```

# Naim's Code

```{r}
alpha = 2
mu = 0
y = 0
n_0 = 1
lambda = n_0 / (1+n_0)
M = 10000
# taken from https://statswithr.github.io/book/inference-and-decision-making-with-multiple-parameters.html#sec:NG-MC
# translated our parameters into theirs
m_0 = mu; n_0 = n_0;  s2_0 = 1; v_0 = alpha
# sample summaries
Y = y
ybar = mean(Y)
s2 = 0#var(Y)
n = length(Y)
# posterior hyperparamters
n_n = n_0 + n
m_n = (n*ybar + n_0*m_0)/n_n
v_n = v_0 + n
s2_n = ((n-1)*s2 + v_0*s2_0 + n_0*n*(m_0 - ybar)^2/n_n)/v_n
# drawing from the posterior, note that the source I am using assume rate instead of scale
psip  = rgamma(M, shape = v_0/2, rate = v_0/2)
mup = rnorm(M, mean = m_n, sd = sqrt(1/psip)/sqrt(n_n)) 
mcmc_samps2 = cbind(mup, psip)
mcmc_samps = draws(m_0, 2, M, y)
summary(mcmc_samps2)
summary(mcmc_samps) # from hillary's code, similar 
par(mfrow = c(2, 1))
hist(mcmc_samps2[,1], breaks = 1000, xlim = c(-5, 5))
hist(mcmc_samps[,1], breaks = 1000, xlim = c(-5, 5))
# calcull
lik2 = dnorm(Y,mean = mcmc_samps2[,1],sd = sqrt(1/mcmc_samps2[,2]))
lik = dnorm(Y,mean = mcmc_samps[,1],sd = sqrt(1/mcmc_samps[,2]))
#HM
mean(1/lik2)^-1
mean(1/lik)^-1
# Modified HM
1/mod_HM_sect2(mcmc_samps2, y = y, mu0 = mu, alpha = alpha, p = 0.98)
1/mod_HM_sect2(mcmc_samps, y = y, mu0 = mu, alpha = alpha, p = 0.98)

# truth
f_y
```




The End